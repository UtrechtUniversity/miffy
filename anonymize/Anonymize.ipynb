{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow example:  To what extent are you a positive person? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps ###\n",
    "0. **Formulate Goal**\n",
    "1. **Determine which variable should be selected to reach goal**\n",
    "2. **Select raw data source**\n",
    "3. **List available information in raw data source**\n",
    "4. **Create dictionary with sensitive info**\n",
    "5. **Create function to search for sensitive info and replace it with pseudo data**\n",
    "____________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import emojis\n",
    "import emoji\n",
    "import regex\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Goal\n",
    "\n",
    "**Develop generic label search function for (instagram) .json** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Variable\n",
    "\n",
    "* Automatically find sensitive user information in all .json files\n",
    "* Automatically change sensitive user information to (pseudo) anonymized key\n",
    "* Automatically create a dictionary with original key and (pseudo) anonymized change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Raw data source\n",
    "\n",
    "**Instagram**\n",
    "\n",
    "Instagram download contains the following folders:\n",
    "\n",
    "* direct  > date folders (YYDDMM) > photos directly send to other users via 'message' on that day\n",
    "* photos  > date folders (YYDDMM) > photos posted on your 'page' that day\n",
    "* videos  > date folders (YYDDMM) > videos posted on your 'page' that day\n",
    "* stories > date folders (YYDDMM) > photos posted on your 'story' that day\n",
    "* profile > date folders (YYDDMM) > photo used as profile picture on that day\n",
    "\n",
    "Instagram download contains the following files (not in folders):\n",
    "0. information_about_you: your primary location (home adress)\n",
    "1. searches: your search info on instagram with corresponding timestamp\n",
    "2. autofill: ? (*'You have no data in this section'*)\n",
    "3. checkout: the email of payment account (N.B. insta if free) \n",
    "4. connections: all your connections with corresponding timestamps (e.g., when did you start following them or vice versa)\n",
    "5. devices: information about the used devices\n",
    "6. likes: likes of media posts and comments of other users with corresponding timestamp\n",
    "7. media: caption of photo posts, video posts, and stories with corresponding timestamp and path to corresponding media (within download)\n",
    "8. seen_content: all content (posts, videos, adds, chains) you've seen on instagram with corresponding timestamp and author (username of poster)\n",
    "9. settings: account setting (allow comments from)\n",
    "10. stories_activities: your activity on story polls of other users\n",
    "11. account_history: info of logged in devices (e.g., ip adress) and registration info (e.g., name, email)\n",
    "12. comments: your comments on other (unknown) users posts with corresponding timestamp\n",
    "13. messages: private messages between you and other users with corresponding timestamps, shared media, links, etc.\n",
    "14. profile: all information about your profile (e.g., username, email, full name, start date, etc.)\n",
    "15. saved: all saved media with corresponding timestamp and owner of media (username)\n",
    "16. uploaded_contacts: ? (*'You have no data in this section'*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = Path('your path to insta data')\n",
    "data = project /'datadownload'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passive files (generated by insta)\n",
    "json_file_you = data / 'information_about_you.json'\n",
    "json_file_autofill = data / 'autofill.json'\n",
    "json_file_pay = data / 'checkout.json'\n",
    "json_file_users = data / 'connections.json'\n",
    "json_file_device = data / 'devices.json'\n",
    "json_file_settings = data / 'settings.json'\n",
    "json_file_account = data / 'account_history.json'\n",
    "json_file_user = data / 'profile.json'\n",
    "json_file_contact = data / 'uploaded_contacts'\n",
    "\n",
    "# Interaction files (generated by users)\n",
    "json_file_like = data / 'likes.json'\n",
    "json_file_med = data / 'media.json'\n",
    "json_file_seen = data / 'seen_content.json'\n",
    "json_file_stories = data / 'stories_activities.json'\n",
    "json_file_com = data / 'comments.json'\n",
    "json_file_mes = data / 'messages.json'\n",
    "json_file_saved = data / 'saved.json'\n",
    "json_file_search = data / 'searches.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. List available information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What sensitive info is where?\n",
    "\n",
    "Files containing 'usernames' \n",
    "* 1. searches.json --> username of other users (direct)\n",
    "* 4. connections.json --> username of other users (direct) (your connections: people following you, or people you follow)\n",
    "* 6. likes.json --> username of other users (direct)\n",
    "* 7. media.json --> username of other users (indirect) (within your caption you can tagg people with @username)\n",
    "* 8. seen_content.json --> username of other (unknown) users (direct)\n",
    "* 10. stories_activities.json --> username of other users (direct)\n",
    "* 11. account_history.json --> registration_info list\n",
    "* 12. comments.json --> username of other (unkown) users (direct + indirect) (within your comment you can tagg people with @username)\n",
    "* 13. messages.json --> username of other users (direct + indirect) (within your caption you can tagg people with @username, but the full names of the users are also used frequently 'hey Kees! how are you?')\n",
    "* 14. profile.json --> username of your account (direct)\n",
    "* 15. saved.json --> username of other users (direct)\n",
    "\n",
    "Files containing other personal info\n",
    "* 0. information_about_you.json --> primary location (home adress)\n",
    "* 3. checkout.json --> payment_account_emails\n",
    "* 5. devices.json --> device_id\n",
    "* 11. account_history.json --> login_history (e.g., ip adress, device id) and registration_info (e.g., name, email)\n",
    "* 14. profile.json --> all profile info (e.g., email, gender, name, link to profile picture, username, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create dictionary with sensitive info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find all 'explicit' usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usernames():\n",
    "    \n",
    "    # Load profile.json to get username of user\n",
    "    with open(json_file_user, encoding = \"utf8\") as json_user:\n",
    "        user = json.load(json_user)\n",
    "    \n",
    "    user = pd.DataFrame.from_dict(user, \n",
    "        orient = 'index').T \n",
    "    \n",
    "    # Load connections.json to get username of all connections\n",
    "    with open(json_file_users, encoding = \"utf8\") as json_users:\n",
    "        users = json.load(json_users)\n",
    "\n",
    "    users = pd.DataFrame.from_dict(users, \n",
    "        orient = 'index').T \n",
    "\n",
    "    users = users.index.values.tolist()\n",
    "    \n",
    "    # Create dictionary with original username as key\n",
    "    dictionary = {}\n",
    "    dictionary = dict.fromkeys(user['username'] , 'NA')\n",
    "    new = dict.fromkeys(users , 'NA')\n",
    "    dictionary.update(new)\n",
    "    \n",
    "    # look for usernames outside of connections \n",
    "    # Saved media\n",
    "    with open(json_file_saved, encoding = \"utf8\") as json_saved:\n",
    "        saved = json.load(json_saved)\n",
    "    \n",
    "    users = pd.DataFrame(saved['saved_media'])[1]\n",
    "    \n",
    "    # Likes\n",
    "    with open(json_file_like, encoding = \"utf8\") as json_likes:\n",
    "        likes = json.load(json_likes)\n",
    "    \n",
    "    user_like = pd.DataFrame(likes['media_likes'])[1]\n",
    "    user_like = user_like.append(pd.DataFrame(likes['comment_likes'])[1])\n",
    "        \n",
    "    # Seen content\n",
    "    with open(json_file_seen, encoding = \"utf8\") as json_seen:\n",
    "        seen = json.load(json_seen)\n",
    "    \n",
    "    user_seen = pd.DataFrame(seen['chaining_seen'])['username']\n",
    "    user_seen = user_seen.append(pd.DataFrame(seen['ads_seen'])['author'])\n",
    "    user_seen = user_seen.append(pd.DataFrame(seen['posts_seen'])['author'])\n",
    "    user_seen = user_seen.append(pd.DataFrame(seen['videos_watched'])['author'])\n",
    "    \n",
    "    # Search media\n",
    "    with open(json_file_search, encoding = \"utf8\") as json_search:\n",
    "        search = json.load(json_search)\n",
    "\n",
    "    user_search = pd.DataFrame(search)['search_click']\n",
    "    \n",
    "    # Media comments\n",
    "    with open(json_file_com, encoding = \"utf8\") as json_comments:\n",
    "        comments = json.load(json_comments)\n",
    "\n",
    "    user_com = pd.DataFrame(comments['media_comments'])[2]\n",
    "    \n",
    "    # Merge all usernames\n",
    "    users = users.append(user_seen)\n",
    "    users = users.append(user_like)\n",
    "    users = users.append(user_search)\n",
    "    users = users.append(user_com)\n",
    "    users = set(users)\n",
    "    \n",
    "    for i in users:\n",
    "        if i in dictionary:\n",
    "            next\n",
    "        else: \n",
    "            dictionary.update({i:'NA'})\n",
    "    \n",
    "    return(dictionary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roosvoor': 'NA',\n",
       " 'beberson': 'NA',\n",
       " 'danielpolosetzky': 'NA',\n",
       " 'sophie_soof': 'NA',\n",
       " 'symonab': 'NA',\n",
       " 'mana.fazel': 'NA',\n",
       " 'evaendema': 'NA',\n",
       " 'zack_from_earth': 'NA',\n",
       " 'jboonstra73': 'NA',\n",
       " '_romyrachel': 'NA',\n",
       " 'lauraderooij': 'NA',\n",
       " 'veerlegewoon': 'NA',\n",
       " 'sophiejacobs1993': 'NA',\n",
       " 'momo_schaap': 'NA',\n",
       " 'mitalipoovs': 'NA',\n",
       " 'bonnievanderlee': 'NA',\n",
       " 'agnesdesl': 'NA',\n",
       " 'theycallmenita': 'NA',\n",
       " 'die_ene_insta': 'NA',\n",
       " 'hannadohle': 'NA',\n",
       " 'jurrekuin': 'NA',\n",
       " 'yaramiora': 'NA',\n",
       " 'faraah.aulia': 'NA',\n",
       " 'bluunie': 'NA',\n",
       " 'tiarmaguvnor': 'NA',\n",
       " 'ingevanooijen': 'NA',\n",
       " 'dieuweertje': 'NA',\n",
       " 'al.bert.0': 'NA',\n",
       " 'annelotte2': 'NA',\n",
       " 'hugomcgurran': 'NA',\n",
       " 'anouckdh': 'NA',\n",
       " 'mitmettoni': 'NA',\n",
       " 'ellinaa': 'NA',\n",
       " 'floor___': 'NA',\n",
       " 'louisebc': 'NA',\n",
       " 'laurameershoek': 'NA',\n",
       " 'kimvuurboom': 'NA',\n",
       " 'dieffiee': 'NA',\n",
       " 'vera.anne.bakker': 'NA',\n",
       " 'tamarabreugelmans': 'NA',\n",
       " 'hannahvanderstok': 'NA',\n",
       " 'tesselbossen': 'NA',\n",
       " 'robinvanschuylenburch': 'NA',\n",
       " 'rafickdemol': 'NA',\n",
       " 'sboogje': 'NA',\n",
       " 'rrougoor': 'NA',\n",
       " 'silviabrouwer': 'NA',\n",
       " 'luuk_pier': 'NA',\n",
       " 'mbruinsma': 'NA',\n",
       " 'chairaserrarens': 'NA',\n",
       " 'juulhuitema': 'NA',\n",
       " 'evatullemans': 'NA',\n",
       " 'charlottegredal': 'NA',\n",
       " 'paula_i.m': 'NA',\n",
       " 'petraormel': 'NA',\n",
       " 'rebecca.gsm': 'NA',\n",
       " 'lizzie_jmo': 'NA',\n",
       " 'daphnee.ch': 'NA',\n",
       " 'serinakragt': 'NA',\n",
       " 'lissmits_': 'NA',\n",
       " 'farliaa': 'NA',\n",
       " 'beertjelohman': 'NA',\n",
       " 'yaylailksoy': 'NA',\n",
       " 'pirosssvl': 'NA',\n",
       " 'guusje002': 'NA',\n",
       " 'adjoayo': 'NA',\n",
       " 'htullemans': 'NA',\n",
       " 'saarhollander': 'NA',\n",
       " 'leonmarijn.s': 'NA',\n",
       " 'marinbaelde': 'NA',\n",
       " 'appelpartje': 'NA',\n",
       " 'doris.daily': 'NA',\n",
       " 'zzzitaboeren': 'NA',\n",
       " 'ashleyhagers': 'NA',\n",
       " 'terencespeyer': 'NA',\n",
       " 'sophieloveminoes': 'NA',\n",
       " 'winonavisuals': 'NA',\n",
       " 'lisadielessen': 'NA',\n",
       " 'aniekdebruijn': 'NA',\n",
       " 'kimnetsanav94': 'NA',\n",
       " 'rik.swart': 'NA',\n",
       " 'photogravic___': 'NA',\n",
       " 'elkedageenkater': 'NA',\n",
       " 'greenroutine_challenge': 'NA',\n",
       " 'mischabenjamin': 'NA',\n",
       " 'bonbonlon': 'NA',\n",
       " 'marrisch16': 'NA',\n",
       " 'prast_bojo': 'NA',\n",
       " 'jutkayik': 'NA',\n",
       " 'mandyxv': 'NA',\n",
       " 'teslaminor': 'NA',\n",
       " 'xroozxx': 'NA',\n",
       " 'daaneus': 'NA',\n",
       " 'nickmoerss': 'NA',\n",
       " 'keskinarikan': 'NA',\n",
       " 'stephanienaomi_': 'NA',\n",
       " 'cafeblek': 'NA',\n",
       " 'ann.eliess': 'NA',\n",
       " 'rosenasrawi': 'NA',\n",
       " 'mtdeklerk': 'NA',\n",
       " 'socialcognito': 'NA',\n",
       " 'konemonu': 'NA',\n",
       " 'anneliekeeeee': 'NA',\n",
       " 'constantaxel': 'NA',\n",
       " 'joycexv': 'NA',\n",
       " 'iva.with.an.i': 'NA',\n",
       " 'meliscetincelik': 'NA',\n",
       " 'karlijn.kooij': 'NA',\n",
       " 'bobbyjane': 'NA',\n",
       " 'alexander.janssen': 'NA',\n",
       " 'ieraa7': 'NA',\n",
       " 'panas6': 'NA',\n",
       " 'samsalasamba': 'NA',\n",
       " 'kalkkunanakki': 'NA',\n",
       " 'serena_cam78': 'NA',\n",
       " 'eline.l': 'NA',\n",
       " 'evelien_dej': 'NA',\n",
       " 'milovb': 'NA',\n",
       " 'de.jan': 'NA',\n",
       " 'martijnvanderstraeten': 'NA',\n",
       " 'kmdennard': 'NA',\n",
       " 'aronvanbaarsen': 'NA',\n",
       " 'lydiwo': 'NA',\n",
       " 'mariana_dq': 'NA',\n",
       " 'reiserida': 'NA',\n",
       " 'yoncabasa': 'NA',\n",
       " 'laraborst': 'NA',\n",
       " 'vandevussevanrijn': 'NA',\n",
       " 'gijoro': 'NA',\n",
       " 'annexevita': 'NA',\n",
       " 'jasmijnreemer': 'NA',\n",
       " 'suzannedezwaan': 'NA',\n",
       " 'charlottehofstee': 'NA',\n",
       " 'femkepaauwe': 'NA',\n",
       " 'millardsamantha': 'NA',\n",
       " 'rik_a_s_brouwer': 'NA',\n",
       " 'catovan': 'NA',\n",
       " 'jolivere': 'NA',\n",
       " 'tesshuigsloot': 'NA',\n",
       " 'dkustebay': 'NA',\n",
       " 'cchderek': 'NA',\n",
       " 'margotmett': 'NA',\n",
       " 'sanderjdw': 'NA',\n",
       " 'mariasiermann': 'NA',\n",
       " 'ribbitwebbo': 'NA',\n",
       " 'lovely.lisl': 'NA',\n",
       " 'thijsjuan': 'NA',\n",
       " 'sophieabrahamse': 'NA',\n",
       " 'stevenvoges': 'NA',\n",
       " 'jasmijnwassing': 'NA',\n",
       " 'jeroen.138': 'NA',\n",
       " 'dorinewd': 'NA',\n",
       " 'niekschuitemaker': 'NA',\n",
       " 'margoootjeee': 'NA',\n",
       " 'noaduizend': 'NA',\n",
       " 'mariannedhk': 'NA',\n",
       " 'joehughesjohnson': 'NA',\n",
       " 'irispleijsier': 'NA',\n",
       " 'mikevzwieten': 'NA',\n",
       " 'ferial_ebm': 'NA',\n",
       " 'freyja_aich': 'NA',\n",
       " 'roh_ree': 'NA',\n",
       " 'nesxxnes': 'NA',\n",
       " 'emiliavsc': 'NA',\n",
       " 'bodaartje': 'NA',\n",
       " 'ritchie_terrence': 'NA',\n",
       " 'femkers': 'NA',\n",
       " 'yinanni': 'NA',\n",
       " 'travelousdreamer': 'NA',\n",
       " 'guidotm': 'NA',\n",
       " 'goktugkilic': 'NA',\n",
       " 'tom_bekkers': 'NA',\n",
       " 'rrwijnker': 'NA',\n",
       " 'evelieneongenae': 'NA',\n",
       " 'rubykeijzer': 'NA',\n",
       " 'nikkibrands': 'NA',\n",
       " 'marijnevb': 'NA',\n",
       " 'vic.bodiut': 'NA',\n",
       " 'smalartlisa': 'NA',\n",
       " 'jaspervdzwaag': 'NA',\n",
       " 'odettebonnema': 'NA',\n",
       " 'goosrobin': 'NA',\n",
       " 'monjeezy': 'NA',\n",
       " 'bdeferrante': 'NA',\n",
       " 'thaizezwart': 'NA',\n",
       " 'sabineklinkhamer': 'NA',\n",
       " 'ivydijkstra': 'NA',\n",
       " 'chrisannerog': 'NA',\n",
       " 'danaesme': 'NA',\n",
       " 'annabanana506': 'NA',\n",
       " 'samw_p': 'NA',\n",
       " 'catsable': 'NA',\n",
       " 'laurensvangurpdesign': 'NA',\n",
       " 'taalvoutjes': 'NA',\n",
       " 'cognito_uva': 'NA',\n",
       " 'talents.of.tno': 'NA',\n",
       " 'thearchbish0pofbanterbury': 'NA',\n",
       " 'hetparool': 'NA',\n",
       " 'nos': 'NA',\n",
       " 'justtattoosz': 'NA',\n",
       " 'littletattoosz': 'NA',\n",
       " 'manbijthondnl': 'NA',\n",
       " 'trust_me_i_am_biologist': 'NA',\n",
       " 'chinupdarling.co': 'NA',\n",
       " 'vjeze_fur': 'NA',\n",
       " 'faberyayo': 'NA',\n",
       " 'gruntenveggieoats': 'NA',\n",
       " 'dumpert': 'NA',\n",
       " 'in_dutch_we_dont_say': 'NA',\n",
       " 'scienceparkmemes': 'NA',\n",
       " 'eenvoud_': 'NA',\n",
       " 'theellenshow': 'NA',\n",
       " 'vancityreynolds': 'NA',\n",
       " 'laekkerby': 'NA',\n",
       " 'dutchess_lazy': 'NA',\n",
       " 'piecesofmindnl': 'NA',\n",
       " 'daan_kins': 'NA',\n",
       " 'zoee_mer': 'NA',\n",
       " 'theschooloflife.amsterdam': 'NA',\n",
       " 'ozzymanreviews': 'NA',\n",
       " 'merazonia_refuge': 'NA',\n",
       " 'boysinthewest69': 'NA',\n",
       " 'nousveerman': 'NA',\n",
       " 'jorisjwbuis': 'NA',\n",
       " 'jessrome13': 'NA',\n",
       " 'neuroseps': 'NA',\n",
       " 'scottyish': 'NA',\n",
       " '_ssimon_': 'NA',\n",
       " 'jorvisje': 'NA',\n",
       " 'thuisaandeamstel': 'NA',\n",
       " 'liekebeemster': 'NA',\n",
       " 'ricodisco12': 'NA',\n",
       " 'tizianahey': 'NA',\n",
       " 'beautiful_minds': 'NA',\n",
       " 'one.line.drawings': 'NA',\n",
       " 'florent_leclercq.art': 'NA',\n",
       " 'some_naked_bodies': 'NA',\n",
       " 'ted': 'NA',\n",
       " 'vintage_en_retro': 'NA',\n",
       " 'asva_studentenunie': 'NA',\n",
       " 'tovervrouwtje': 'NA',\n",
       " 'carlosplatierluna': 'NA',\n",
       " 'groosink': 'NA',\n",
       " 'ninismili': 'NA',\n",
       " 'joanderuijter': 'NA',\n",
       " 'shellysterk': 'NA',\n",
       " 'imkewieffer': 'NA',\n",
       " 'minnekoole': 'NA',\n",
       " 'serrarenschaira': 'NA',\n",
       " 'puckmia': 'NA',\n",
       " 'winonaolympia': 'NA',\n",
       " 'zack.koster': 'NA',\n",
       " 'physics.ig': 'NA',\n",
       " 'natgeo': 'NA',\n",
       " 'nosstories': 'NA',\n",
       " 'sarcasm_only': 'NA',\n",
       " 'czweerus': 'NA',\n",
       " 'albanvoppel': 'NA',\n",
       " 'creaamsterdam': 'NA',\n",
       " 'little.tattoos': 'NA',\n",
       " 'lilmighty94': 'NA',\n",
       " 'casperzweerus': 'NA',\n",
       " 'jana_ida_': 'NA',\n",
       " 'rorymcsheffrey': 'NA',\n",
       " 'serrie_b': 'NA',\n",
       " 'crunchyzoah': 'NA',\n",
       " 'noenbrouwer': 'NA',\n",
       " 'juliavanvuuren': 'NA',\n",
       " 'hoiamber': 'NA',\n",
       " 'liefsaiah': 'NA',\n",
       " 'nas_ioui': 'NA',\n",
       " 'missmontreal_': 'NA',\n",
       " 'noracelineramakers': 'NA',\n",
       " 'jeske_janssen': 'NA',\n",
       " 'frank3fm': 'NA',\n",
       " 'jochemmyjer': 'NA',\n",
       " 'dwddtv': 'NA',\n",
       " 'kakhiel': 'NA',\n",
       " 'de_speld': 'NA',\n",
       " 'arjenlubach': 'NA',\n",
       " 'streetlabtv': 'NA',\n",
       " 'debroervanroos': 'NA',\n",
       " 'jan_versteegh': 'NA',\n",
       " 'leavecaricealone': 'NA',\n",
       " 'mitchellpeloso': 'NA',\n",
       " 'geraldine_kemper': 'NA',\n",
       " 'at5.nl': 'NA',\n",
       " 'sarahhyland': 'NA',\n",
       " 'irisgombert': 'NA',\n",
       " 'emmawatson': 'NA',\n",
       " 'emilia_clarke': 'NA',\n",
       " 'sophiet': 'NA',\n",
       " 'maisie_williams': 'NA',\n",
       " 'colesprouse': 'NA',\n",
       " 'tumlhr': 'NA',\n",
       " 'vandervoortkarlijn': 'NA',\n",
       " 'marijkevhilst': 'NA',\n",
       " 'tanakamax': 'NA',\n",
       " 'drawinggpencil': 'NA',\n",
       " 'drawings': 'NA',\n",
       " 'sammyheutz21': 'NA',\n",
       " 'yazzzzo': 'NA',\n",
       " '9gag': 'NA',\n",
       " 'mooswilhelm': 'NA',\n",
       " 'gunesxo': 'NA',\n",
       " 'frederiquedanielle': 'NA',\n",
       " 'hannahtullemans': 'NA',\n",
       " 'diedeleeuw': 'NA',\n",
       " 'elzinga.studio': 'NA',\n",
       " 'blokkkie': 'NA',\n",
       " 'bobbyoudshoorn': 'NA',\n",
       " 'tobiasspecker': 'NA',\n",
       " 'art': 'NA',\n",
       " 'selflove_academy': 'NA',\n",
       " 'harmenabenga': 'NA',\n",
       " 'maaster_lak': 'NA',\n",
       " 'roeiendoejebijokeanos7933': 'NA',\n",
       " 'yanart_drawing': 'NA',\n",
       " 'pink_cheese_one': 'NA',\n",
       " 'hetpauperparadijs': 'NA',\n",
       " 'marns': 'NA',\n",
       " 'design_qra': 'NA',\n",
       " 'dadrogist': 'NA',\n",
       " 'doorie78': 'NA',\n",
       " 'calvepindakaasofficial': 'NA',\n",
       " 'andreagrecoart': 'NA',\n",
       " 'blakelively': 'NA',\n",
       " 'leekillust': 'NA',\n",
       " 'nathanhgshore': 'NA',\n",
       " 'workoutcode': 'NA',\n",
       " 'arts_moonlight': 'NA',\n",
       " 'cluse': 'NA',\n",
       " 'spuitenenslikken': 'NA',\n",
       " 'inspirerendleven': 'NA',\n",
       " 'knorrnederland': 'NA',\n",
       " 'royalcaninnl': 'NA',\n",
       " 'ems_050': 'NA',\n",
       " 'alisongredal': 'NA',\n",
       " 'crazyvoicess': 'NA',\n",
       " 'jumbo': 'NA',\n",
       " 'viralartz': 'NA',\n",
       " 'bellasfashion94': 'NA',\n",
       " 'saskia.brouwer': 'NA',\n",
       " 'gymposition': 'NA',\n",
       " 'wonenopoostenburg': 'NA',\n",
       " 'melissakerver': 'NA',\n",
       " 'langlevedeliefdenl': 'NA',\n",
       " 'fitzandhuxley': 'NA',\n",
       " 'omroepbnnvara': 'NA',\n",
       " 'hannahbarrettyoga': 'NA',\n",
       " 'woonenzo': 'NA',\n",
       " 'wholesomeculture': 'NA',\n",
       " 'awwwfeed': 'NA',\n",
       " 'seysten': 'NA',\n",
       " 'noordriessen': 'NA',\n",
       " 'sigridtennapel': 'NA',\n",
       " 'son.of.joyce': 'NA',\n",
       " 'purpleheartcraft': 'NA',\n",
       " 'journe__': 'NA',\n",
       " 'sander_van_rijn': 'NA',\n",
       " 'vanstekkarl': 'NA',\n",
       " 'the.pinklemonade': 'NA',\n",
       " 'quincykrijger': 'NA',\n",
       " 'unclewol': 'NA',\n",
       " 'yoga.addictgirl': 'NA',\n",
       " 'katha.linaa': 'NA',\n",
       " 'johnnydemolofficial': 'NA',\n",
       " 'mcdonaldsnl': 'NA',\n",
       " 'kitharingtonig': 'NA',\n",
       " 'cityshapesnl': 'NA',\n",
       " 'judithvrolijk': 'NA',\n",
       " 'kendalljenner': 'NA',\n",
       " 'just.lifequotes': 'NA',\n",
       " 'zaful': 'NA',\n",
       " 'brenthockley': 'NA',\n",
       " 'marlene.apple': 'NA',\n",
       " 'lola.burke_': 'NA',\n",
       " 'lambleystuart': 'NA',\n",
       " 'avisualshoot': 'NA',\n",
       " 'arts_promoter': 'NA',\n",
       " 'ilsedelangemusic': 'NA',\n",
       " 'gymdaily.nl': 'NA',\n",
       " 'noririnhayashi': 'NA',\n",
       " 'i_m_workout': 'NA',\n",
       " 'vattenfallnl': 'NA',\n",
       " 'sketch_dailydose': 'NA',\n",
       " 'fairphone': 'NA',\n",
       " 'mitchelkoppers': 'NA',\n",
       " 'scottgshore': 'NA',\n",
       " 'artzincolor': 'NA',\n",
       " 'emilyy_fitness': 'NA',\n",
       " 'r.a.a.k.t': 'NA',\n",
       " 'theavanderparre': 'NA',\n",
       " 'linda': 'NA',\n",
       " 'pleunbierbooms': 'NA',\n",
       " 'tutorialdegirl': 'NA',\n",
       " 'arts.realism': 'NA',\n",
       " 'anastasiakarachristou': 'NA',\n",
       " 'simonkeizer': 'NA',\n",
       " 'milou_gr': 'NA',\n",
       " 'mline_nl': 'NA',\n",
       " 'danio_nl': 'NA',\n",
       " 'yucn.li': 'NA',\n",
       " 'adam.official': 'NA',\n",
       " 'karniale': 'NA',\n",
       " 'soyochii': 'NA',\n",
       " 'omroepvpro': 'NA',\n",
       " 'selektta': 'NA',\n",
       " 'rab._.an': 'NA',\n",
       " 'lilireinhart': 'NA',\n",
       " 'sivan.ka': 'NA',\n",
       " 'donjavdl': 'NA',\n",
       " 'hagecharlotte': 'NA',\n",
       " 'wiezewasjes': 'NA',\n",
       " 'jozo.salt': 'NA',\n",
       " 'homeabguide': 'NA',\n",
       " 'yoga.tutorials': 'NA',\n",
       " 'ronald.vanrijn.3': 'NA',\n",
       " 'sophiekasaei_': 'NA',\n",
       " 'arts.mrv': 'NA',\n",
       " 'kicksnarebass': 'NA',\n",
       " 'mutemuse.official': 'NA',\n",
       " 'luzaa_b': 'NA',\n",
       " 'instagram': 'NA',\n",
       " 'bol_com': 'NA',\n",
       " 'instatructor': 'NA',\n",
       " 'aaroncgshore': 'NA',\n",
       " 'ashleigh_jordan': 'NA',\n",
       " 'singingshiz': 'NA',\n",
       " 'zwokbor': 'NA',\n",
       " 'plantje.nl': 'NA',\n",
       " 'barbara.beurmanjer': 'NA',\n",
       " 'waarutrechteet': 'NA',\n",
       " 'posterstore': 'NA',\n",
       " 'alfieeallen': 'NA',\n",
       " '10e': 'NA',\n",
       " 'blank.sunglasses': 'NA',\n",
       " 'art.nights': 'NA',\n",
       " 'yaeltuasela': 'NA',\n",
       " 'br1tth': 'NA',\n",
       " 'alpentocht': 'NA',\n",
       " 'kiezelstien': 'NA',\n",
       " 'snaptweet': 'NA',\n",
       " 'argeta3803': 'NA',\n",
       " 'marleenjacobs4': 'NA',\n",
       " 'monicageuze': 'NA',\n",
       " 'loccitane_nl': 'NA',\n",
       " 'abdullahsaylam2019': 'NA',\n",
       " 'fitmoral': 'NA',\n",
       " 'de_volkskrant': 'NA',\n",
       " 'pastinaakt': 'NA',\n",
       " 'megadumpnl': 'NA',\n",
       " 'ecobird.nl': 'NA',\n",
       " 'rumag': 'NA',\n",
       " 'babemometv': 'NA',\n",
       " 'nolangould': 'NA',\n",
       " 'dyson1411': 'NA',\n",
       " 'selfcrebear': 'NA',\n",
       " 'vid_vocals': 'NA',\n",
       " 'yogavered': 'NA',\n",
       " 'tmobilenederland': 'NA',\n",
       " 'poptradingcompany': 'NA',\n",
       " 'art.ig': 'NA',\n",
       " 'spanederland': 'NA',\n",
       " 'annanooshin': 'NA',\n",
       " 'alaa.aloulabi': 'NA',\n",
       " 'tattoo.kobenski': 'NA',\n",
       " 'keukenmarkthal.nl2': 'NA',\n",
       " 'levis_nl': 'NA',\n",
       " 'evanorah': 'NA',\n",
       " 'juliaverheyden': 'NA',\n",
       " 'alexander.pechtold': 'NA',\n",
       " 'grundig.nl': 'NA',\n",
       " 'rara_waarislara': 'NA',\n",
       " 'goedesier2015': 'NA',\n",
       " 'cheyenne_on_track': 'NA',\n",
       " 'alyno94': 'NA',\n",
       " 'sigridfitness': 'NA',\n",
       " 'nickschilder': 'NA',\n",
       " 'happinez': 'NA',\n",
       " 'alecmaas': 'NA',\n",
       " 'taylorswift': 'NA',\n",
       " 'mayambili': 'NA',\n",
       " 'luukluukluukhoi': 'NA',\n",
       " 'miraalou': 'NA',\n",
       " 'yogimat.nl': 'NA',\n",
       " 'skinnypt': 'NA',\n",
       " 'humbertotan': 'NA',\n",
       " 'degrotevragen': 'NA',\n",
       " 'benefitnetherlands': 'NA',\n",
       " 'bodineschotsman': 'NA',\n",
       " 'wonderful.world.pic': 'NA',\n",
       " 'borisbrussel': 'NA',\n",
       " 'phalerieau': 'NA',\n",
       " 'synapsemebaby': 'NA',\n",
       " 'oxfamnovib': 'NA',\n",
       " 'mediumhairstyles': 'NA',\n",
       " 'floraplantbased': 'NA',\n",
       " 'liliankropman': 'NA',\n",
       " 'hero.fruit': 'NA',\n",
       " 'beyonce': 'NA',\n",
       " 'douwebob': 'NA',\n",
       " 'albertheijn': 'NA',\n",
       " 'nederlandseloterij': 'NA',\n",
       " 'lnstababies': 'NA',\n",
       " 'space_girls_from_earth': 'NA',\n",
       " 'thegalaxylovesu': 'NA',\n",
       " '3npo': 'NA',\n",
       " 'nazihasalami': 'NA',\n",
       " 'gemeenteamsterdam': 'NA',\n",
       " 'worldxvoice': 'NA',\n",
       " 'yoga.goodvibes': 'NA',\n",
       " 'annaboogaard': 'NA',\n",
       " 'jatuur': 'NA',\n",
       " 'rijksoverheid.nl': 'NA',\n",
       " 'gumnl': 'NA',\n",
       " 'huuskes9799': 'NA',\n",
       " 'h.noremax': 'NA',\n",
       " 'agata1577': 'NA',\n",
       " 'fitmethods': 'NA',\n",
       " 'zbynekkysela': 'NA',\n",
       " 'eneco': 'NA',\n",
       " 'sketch.instadaily': 'NA',\n",
       " 'veg_drawings': 'NA',\n",
       " 'fankling_elliot': 'NA',\n",
       " 'karlijntjeee7': 'NA',\n",
       " 'pinkmau___': 'NA',\n",
       " 'vivazschoonhoven': 'NA',\n",
       " 'maroua93': 'NA',\n",
       " 'amstelveld_i': 'NA',\n",
       " 'sweetcatsgo': 'NA',\n",
       " 'justuszw': 'NA',\n",
       " 'twothirds_bcn': 'NA',\n",
       " 'arts.share.page': 'NA',\n",
       " 'lupusdepoes': 'NA',\n",
       " 'diversity.talks': 'NA',\n",
       " 'roodzwartinjehart': 'NA',\n",
       " 'art_overnight': 'NA',\n",
       " 'nordaceofficial': 'NA',\n",
       " 'alexandernl': 'NA',\n",
       " 'renevnleeuwen': 'NA',\n",
       " 'guus.meeuwis': 'NA',\n",
       " 'samincn': 'NA',\n",
       " 'berryvanbeek2': 'NA',\n",
       " 'playgwent': 'NA',\n",
       " 'sjoemeliers': 'NA',\n",
       " 'teffoweissbescheid': 'NA',\n",
       " 'woahyoga': 'NA',\n",
       " '_reina_yamada_': 'NA',\n",
       " 'remibeer': 'NA',\n",
       " 'awhpaint': 'NA',\n",
       " 'buzzfeedtasty': 'NA',\n",
       " 'timsenders': 'NA',\n",
       " 'doutzen': 'NA',\n",
       " 'wjanssen27': 'NA',\n",
       " 'noah_eklu': 'NA',\n",
       " 'mawjoe.iq': 'NA',\n",
       " 'saintandsofia': 'NA',\n",
       " 'nicolettekluijver_': 'NA',\n",
       " 'jeroenschutt': 'NA',\n",
       " 'diabsteph': 'NA',\n",
       " 'zacefron': 'NA',\n",
       " 'asserroeiclub': 'NA',\n",
       " 'jelkavanhouten': 'NA',\n",
       " 'sneakerdistrict': 'NA',\n",
       " 'kn0wva': 'NA',\n",
       " 'thdrawing': 'NA',\n",
       " 'karolinamysliwiec': 'NA',\n",
       " 'haveaseat.nu': 'NA',\n",
       " 'being.memyselfandi': 'NA',\n",
       " 'wotskiewoutofski': 'NA',\n",
       " 'igtattoogirls': 'NA',\n",
       " 'luchtverkeersleiding': 'NA',\n",
       " 'musicfication': 'NA',\n",
       " 'lily11277': 'NA',\n",
       " 'trekpleister4856': 'NA',\n",
       " 'omfgvoice1': 'NA',\n",
       " 'chloegshore1': 'NA',\n",
       " 'nico.rnz': 'NA',\n",
       " 'loederloutje': 'NA',\n",
       " 'newyorkermag': 'NA',\n",
       " 'chantaljanzen.official': 'NA',\n",
       " 'blackworknow': 'NA',\n",
       " 'cinemien': 'NA',\n",
       " 'digsternl': 'NA',\n",
       " 'theodd1sout_daily': 'NA',\n",
       " 'nrcnl': 'NA',\n",
       " 'visa_nederland': 'NA',\n",
       " 'abs_at_home': 'NA',\n",
       " 'eyedrawing': 'NA',\n",
       " 'berberhumalda': 'NA',\n",
       " 'cindyfrench04': 'NA',\n",
       " 'primevideonl': 'NA',\n",
       " 'lidlnederland': 'NA',\n",
       " 'susanne_reiners': 'NA',\n",
       " 'florencewilmetjedansen': 'NA',\n",
       " 'sligro': 'NA',\n",
       " 'priyanka_kurdikeri': 'NA',\n",
       " 'ameubel': 'NA',\n",
       " 'koenroelink': 'NA',\n",
       " 'bogaard_keukensenbadkamers': 'NA',\n",
       " 'sarka_yoga': 'NA',\n",
       " 'selectdiyss': 'NA',\n",
       " 'athinaki_mou': 'NA',\n",
       " 'backpack1952': 'NA',\n",
       " 'iciparisxlnl': 'NA',\n",
       " 'intratuin_nederland': 'NA',\n",
       " 'desperados': 'NA',\n",
       " 'gymglobal': 'NA',\n",
       " 'yogadailypractice': 'NA',\n",
       " 'tijmenkappen': 'NA',\n",
       " 'nespresso.nl': 'NA',\n",
       " 'daanboom': 'NA',\n",
       " 'yogaalignment': 'NA',\n",
       " 'arts_terra': 'NA',\n",
       " 'lynn_deputter': 'NA',\n",
       " 'stormdennis': 'NA',\n",
       " 'sebastianklawikowski': 'NA',\n",
       " 'gymtouches': 'NA',\n",
       " 'jeroentjes': 'NA',\n",
       " 'gemwhelan': 'NA',\n",
       " 'arielwinter': 'NA',\n",
       " 'doomsdayco': 'NA',\n",
       " 'autodropnl': 'NA',\n",
       " 'bravafabrics': 'NA',\n",
       " 'sparnederland': 'NA',\n",
       " 'worldofmusic': 'NA',\n",
       " 'badkamerwinkel.nl': 'NA',\n",
       " 'liptonicetea4234': 'NA',\n",
       " 'portrait_viral': 'NA',\n",
       " 'level9921': 'NA',\n",
       " 'cellydrw': 'NA',\n",
       " 'altijdspeciaaldroogbloemen': 'NA',\n",
       " 'britneyspears': 'NA',\n",
       " 'justinbieber': 'NA',\n",
       " 'lieverkips': 'NA',\n",
       " 'shapingnewtomorrow': 'NA',\n",
       " 'aegnederland': 'NA',\n",
       " 'zalando': 'NA',\n",
       " 'artmotivators': 'NA',\n",
       " 'pauletteceyrat': 'NA',\n",
       " 'leonardodicaprio': 'NA',\n",
       " '8fact': 'NA',\n",
       " 'sticht4533': 'NA',\n",
       " 'fubiz': 'NA',\n",
       " 'damescinco': 'NA',\n",
       " 'fitfemalesclub': 'NA',\n",
       " 'jesseklaver': 'NA',\n",
       " 'amazingglobepix': 'NA',\n",
       " 'artstrending': 'NA',\n",
       " 'gymvascular': 'NA',\n",
       " 'buildiy.nl': 'NA',\n",
       " 'vrlfit': 'NA',\n",
       " 'sketchsecrets': 'NA',\n",
       " 'brenger.nl': 'NA',\n",
       " 'veloretti': 'NA',\n",
       " 'maradaamen': 'NA',\n",
       " 'z.biere': 'NA',\n",
       " 'sculptlifestyle': 'NA',\n",
       " 'laurencekingpub_nl': 'NA',\n",
       " 'andrea_st14': 'NA',\n",
       " 'marnix.ackermans': 'NA',\n",
       " 'rosiesikkel': 'NA',\n",
       " 'sara.brust': 'NA',\n",
       " 'dennizgoren': 'NA',\n",
       " 'gstarraw': 'NA',\n",
       " 'stevie_bear': 'NA',\n",
       " 'baderquamar': 'NA',\n",
       " 'm.psikheb': 'NA',\n",
       " 'claras.conscious.closet': 'NA',\n",
       " 'vibetutoriais': 'NA',\n",
       " 'hollygshore': 'NA',\n",
       " 'kharim_amier': 'NA',\n",
       " 'selenagomez': 'NA',\n",
       " 'nicole.rutten1': 'NA',\n",
       " 'og3ne': 'NA',\n",
       " 'linstaphoto': 'NA',\n",
       " '7usam86': 'NA',\n",
       " 'sebwabo': 'NA',\n",
       " 'lzwvocals': 'NA',\n",
       " 'illustrationow': 'NA',\n",
       " 'lustellie': 'NA',\n",
       " 'oreo': 'NA',\n",
       " 'marijederoode': 'NA',\n",
       " 'pleuniveen': 'NA',\n",
       " 'helena0sofia': 'NA',\n",
       " 'globalcreatived': 'NA',\n",
       " 'happysocks': 'NA',\n",
       " 'potterywitch': 'NA',\n",
       " 'art.dunyaa': 'NA',\n",
       " 'peterpannekoek': 'NA',\n",
       " 'ellehell': 'NA',\n",
       " 'kanzi_nl_appel': 'NA',\n",
       " 'enactusuva1058': 'NA',\n",
       " 'netflixing': 'NA',\n",
       " 'proficuriosi': 'NA',\n",
       " 'lizekorpie': 'NA',\n",
       " 'livianapoleon': 'NA',\n",
       " 'hoagard': 'NA',\n",
       " 'cobyvanbeeren': 'NA',\n",
       " 'starsgenesis': 'NA',\n",
       " 'thomas_rap': 'NA',\n",
       " 'sarashakeel': 'NA',\n",
       " 'smscontent.com33': 'NA',\n",
       " 'ying_fll': 'NA',\n",
       " 'florianwirsing': 'NA',\n",
       " 'peterdinklage': 'NA',\n",
       " 'jasperdemollin': 'NA',\n",
       " 'tamaris_official': 'NA',\n",
       " 'wendyvandijk3': 'NA',\n",
       " 'frankweiss1731': 'NA',\n",
       " 'jancornelisblokhuis': 'NA',\n",
       " 'culimaat': 'NA',\n",
       " '_khads._': 'NA',\n",
       " 'mattiemarieke': 'NA',\n",
       " 'degourmetkat_nl': 'NA',\n",
       " 'by_daisies': 'NA',\n",
       " 'camera_duels': 'NA',\n",
       " 'ania_75': 'NA',\n",
       " 'linkedin': 'NA',\n",
       " 'felinedewit': 'NA',\n",
       " 'arts2love': 'NA',\n",
       " 'marty_gshore': 'NA',\n",
       " 'modernartt': 'NA',\n",
       " 'anna.ol_ballet': 'NA',\n",
       " 'anaisgonzalez_3': 'NA',\n",
       " 'studiekeuze1231731': 'NA',\n",
       " 'ikonicfitness': 'NA',\n",
       " 'nutsa_nanuashvili': 'NA',\n",
       " 'kimfrench87': 'NA',\n",
       " 'vmbodocent': 'NA',\n",
       " 'how__to__draw': 'NA',\n",
       " 'jeffreykoole': 'NA',\n",
       " 'anwb8557': 'NA',\n",
       " 'mileycyrus': 'NA',\n",
       " 'sven_wientjes': 'NA',\n",
       " 'howtopracticeyoga': 'NA',\n",
       " 'elisevaneijk': 'NA',\n",
       " 'damnvocals21': 'NA',\n",
       " 'anwb_rijopleiding': 'NA',\n",
       " 'short_haircuts': 'NA',\n",
       " 'official_waylon_music': 'NA',\n",
       " 'samsungnederland': 'NA',\n",
       " 'maracimatoribus': 'NA',\n",
       " 'fashions.tv': 'NA',\n",
       " 'omgvoices': 'NA',\n",
       " 'gymgirlcrew': 'NA',\n",
       " 'mauskidss': 'NA',\n",
       " 'bregjeschreuders': 'NA',\n",
       " '_globalart_': 'NA',\n",
       " 'smithareen': 'NA',\n",
       " 'unoxnl': 'NA',\n",
       " 'ladygaga': 'NA',\n",
       " 'kimkardashian': 'NA',\n",
       " 'vickypattison': 'NA',\n",
       " 'jennifervandenberg_': 'NA',\n",
       " 'adele': 'NA',\n",
       " 'bettenoortje': 'NA',\n",
       " 'mona_nederland': 'NA',\n",
       " 'dannygraveland': 'NA',\n",
       " 'above.art.ru': 'NA',\n",
       " 'watercolor': 'NA',\n",
       " 'gameofthrones': 'NA',\n",
       " 'mijnliefsteboek': 'NA',\n",
       " 'nathalieemmanuel': 'NA',\n",
       " 'art.academy': 'NA',\n",
       " 'debezigebij': 'NA',\n",
       " 'arianagrande': 'NA',\n",
       " 'ericanthonyj': 'NA',\n",
       " 'npo3fm': 'NA',\n",
       " 'muhammedsalah_': 'NA',\n",
       " 'dennisweeningofficial': 'NA',\n",
       " 'diytraining': 'NA',\n",
       " 'hastak._': 'NA',\n",
       " 'bella.ruis': 'NA',\n",
       " 'kjapa': 'NA',\n",
       " 'broodnet': 'NA',\n",
       " 'real_vocals_': 'NA',\n",
       " 'stijnvanvliet': 'NA',\n",
       " 'linjerco': 'NA',\n",
       " 'casadicassa': 'NA',\n",
       " 'globaltalents': 'NA',\n",
       " 'dejeugd': 'NA',\n",
       " 'geartsjemb': 'NA',\n",
       " 'pencil_arts_group': 'NA',\n",
       " 'im.gurbender.official': 'NA',\n",
       " 'lumiere_benelux': 'NA',\n",
       " 'vocalupload': 'NA',\n",
       " 'artdaily_viral': 'NA',\n",
       " 'flxmitnacht': 'NA',\n",
       " 'heleenkoning': 'NA',\n",
       " 'bebeautymood': 'NA',\n",
       " 'art_dailydose': 'NA',\n",
       " 'maan.de.st': 'NA',\n",
       " 'lovricdean': 'NA',\n",
       " 'dekoffiejongens': 'NA',\n",
       " 'gymalpha': 'NA',\n",
       " 'ranzijntuindier': 'NA',\n",
       " 'npo.nl': 'NA',\n",
       " 'gverbaan': 'NA',\n",
       " 'roxartss': 'NA',\n",
       " 'gijoelle23': 'NA',\n",
       " 'ddlovato': 'NA'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usernames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find all names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract name of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Roos': 'NA'}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def names():\n",
    "    \n",
    "    # Load profile.json to get name of user\n",
    "    with open(json_file_account, encoding = \"utf8\") as json_user:\n",
    "        name = json.load(json_user)\n",
    "\n",
    "    # Create dictionary\n",
    "    name_dic = {}\n",
    "    name_dic = {name['registration_info']['registration_username']: 'NA'}\n",
    "\n",
    "    return(name_dic)\n",
    "\n",
    "names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract mail of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vladimirvladimirina@gmail.com': 'NA'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mail():\n",
    "    \n",
    "    # Load profile.json to get username of user\n",
    "    with open(json_file_user, encoding = \"utf8\") as json_user:\n",
    "        user = json.load(json_user)\n",
    "    \n",
    "    mail_dic = {}\n",
    "    mail_dic = {user['email']: 'NA'}\n",
    "    \n",
    "    return(mail_dic)\n",
    "\n",
    "mail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to find names in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, encoding = \"utf8\") as f:\n",
    "        data =json.loads(f.read())\n",
    "    return data\n",
    "\n",
    "mydata = read_json(json_file_mes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pii(string):\n",
    "    \"\"\"List all proper nouns, email adresses and phone nrs in a given string\"\"\"\n",
    "    \n",
    "    email_regex = \"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\"\n",
    "    mob_regex = \"(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})\"\n",
    "    \n",
    "    processed = nlp(string)\n",
    "    pii = list()\n",
    "    \n",
    "    for token in processed:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            pii.append(token.text)\n",
    "        elif re.search(mob_regex, str(token)):\n",
    "            pii.append(token.text)\n",
    "        elif re.search(email_regex, token.text):\n",
    "            pii.append(token.text)\n",
    "        \n",
    "    return pii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values(obj, key):\n",
    "    \"\"\"Pull all values of specified key from nested JSON.\"\"\"\n",
    "    arr = []\n",
    "\n",
    "    def extract(obj, arr, key):\n",
    "        \"\"\"Recursively search for values of key in JSON tree.\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            for k, v in obj.items():\n",
    "                if k == key:\n",
    "                    arr.append(v)         \n",
    "                if isinstance(v, (dict, list)):\n",
    "                    extract(v, arr, key)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                extract(item, arr, key)\n",
    "        return arr\n",
    "\n",
    "    results = extract(obj, arr, key)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract senders (usernames) from messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adjoayo',\n",
       " 'ann.eliess',\n",
       " 'annexevita',\n",
       " 'anouckdh',\n",
       " 'appelpartje',\n",
       " 'beberson',\n",
       " 'beertjelohman',\n",
       " 'chairaserrarens',\n",
       " 'charlottehofstee',\n",
       " 'danaesme',\n",
       " 'dieffiee',\n",
       " 'doris.daily',\n",
       " 'evaendema',\n",
       " 'farliaa',\n",
       " 'guusje002',\n",
       " 'hannadohle',\n",
       " 'htullemans',\n",
       " 'ingevanooijen',\n",
       " 'irisgombert',\n",
       " 'jaspervdzwaag',\n",
       " 'jboonstra73',\n",
       " 'jolivere',\n",
       " 'juulhuitema',\n",
       " 'kimnetsanav94',\n",
       " 'kmdennard',\n",
       " 'leonmarijn.s',\n",
       " 'lissmits_',\n",
       " 'lizzie_jmo',\n",
       " 'louisebc',\n",
       " 'mariannedhk',\n",
       " 'marinbaelde',\n",
       " 'mikevzwieten',\n",
       " 'momo_schaap',\n",
       " 'neuroseps',\n",
       " 'noaduizend',\n",
       " 'pirosssvl',\n",
       " 'rafickdemol',\n",
       " 'roh_ree',\n",
       " 'roosvoor',\n",
       " 'rrougoor',\n",
       " 'saarhollander',\n",
       " 'samsalasamba',\n",
       " 'serinakragt',\n",
       " 'sophie_soof',\n",
       " 'suzannedezwaan',\n",
       " 'tamarabreugelmans',\n",
       " 'tesselbossen',\n",
       " 'theycallmenita',\n",
       " 'tiarmaguvnor',\n",
       " 'vandevussevanrijn',\n",
       " 'veerlegewoon',\n",
       " 'yaylailksoy'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senders = extract_values(mydata,'sender')\n",
    "set(senders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All senders are in dictionary\n"
     ]
    }
   ],
   "source": [
    "# Check if there are unknown senders in the list\n",
    "dictionary = usernames()\n",
    "\n",
    "round = 0\n",
    "for i in senders:\n",
    "    if i in dictionary:\n",
    "        next\n",
    "    else: \n",
    "        round = round + 1\n",
    "        print(\"There are unknown senders!\")\n",
    "        \n",
    "if (round == 0):\n",
    "    print(\"All senders are in dictionary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract names from messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load messages.json\n",
    "with open(json_file_mes, encoding = \"utf8\") as json_messages:\n",
    "    message = json.load(json_messages)\n",
    "\n",
    "messages = pd.DataFrame.from_dict(message[1], \n",
    "                                          orient = 'index').T\n",
    "for i in range(2, len(message)):\n",
    "    # Create dataframe    \n",
    "    messages = messages.append(pd.DataFrame.from_dict(message[i], \n",
    "                                          orient = 'index').T)\n",
    "\n",
    "# Generate dataframe from message conversation \n",
    "messages_conversation = pd.DataFrame(messages['conversation'].dropna().values.tolist())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>roosvoor</td>\n",
       "      <td>Haha lekkaahh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>beertjelohman</td>\n",
       "      <td>Ja sowieso!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>roosvoor</td>\n",
       "      <td>Maar kan dus alleen maar beter wordn 💪🎉</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>roosvoor</td>\n",
       "      <td>Lekker begin 😅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roosvoor</td>\n",
       "      <td>Haha o nooooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1671</td>\n",
       "      <td>roosvoor</td>\n",
       "      <td>Haha ja als je niet in dat huis moet zitten we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1672</td>\n",
       "      <td>jaspervdzwaag</td>\n",
       "      <td>Hahah dit is best grappig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1673</td>\n",
       "      <td>doris.daily</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1674</td>\n",
       "      <td>roosvoor</td>\n",
       "      <td>Hahahaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>doris.daily</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1676 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sender                                               text\n",
       "0          roosvoor                                      Haha lekkaahh\n",
       "1     beertjelohman                                        Ja sowieso!\n",
       "2          roosvoor            Maar kan dus alleen maar beter wordn 💪🎉\n",
       "3          roosvoor                                     Lekker begin 😅\n",
       "4          roosvoor                                      Haha o nooooo\n",
       "...             ...                                                ...\n",
       "1671       roosvoor  Haha ja als je niet in dat huis moet zitten we...\n",
       "1672  jaspervdzwaag                       Hahah dit is best grappig...\n",
       "1673    doris.daily                                                NaN\n",
       "1674       roosvoor                                           Hahahaha\n",
       "1675    doris.daily                                                NaN\n",
       "\n",
       "[1676 rows x 2 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = messages_conversation[{'text', 'sender'}]\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dutch: spacy.load(\"nl_core_news_sm\")\n",
    "# For english: spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import nl_core_news_sm\n",
    "\n",
    "nlp = nl_core_news_sm.load()\n",
    " \n",
    "def get_pii(string):\n",
    "    \"\"\"List all proper nouns, email adresses and phone nrs in a given string\"\"\"\n",
    "\n",
    "    email_regex = \"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\"\n",
    "    mob_regex = \"(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})\"\n",
    "\n",
    "    processed = nlp(string)\n",
    "    pii = list()\n",
    "\n",
    "    for token in processed:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            pii.append(token.text)\n",
    "        elif re.search(mob_regex, str(token)):\n",
    "            pii.append(token.text)\n",
    "        elif re.search(email_regex, token.text):\n",
    "            pii.append(token.text)\n",
    "\n",
    "    return pii\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list with all nouns (hopefully including all names) and corresponding senders\n",
    "nouns = list()\n",
    "sender = list()\n",
    "\n",
    "for i in range(0,len(mydata)):\n",
    "    my_text = mydata['text'][i]\n",
    "    if pd.isnull(my_text):\n",
    "        next\n",
    "    else:\n",
    "        nouns.append(get_pii(my_text))\n",
    "        sender.append(mydata['sender'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>roosvoor</td>\n",
       "      <td>[lekkaahh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>roosvoor</td>\n",
       "      <td>[🎉]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>roosvoor</td>\n",
       "      <td>[nooooo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>beertjelohman</td>\n",
       "      <td>[ja, zooo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roosvoor</td>\n",
       "      <td>[quality, brush]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>mariannedhk</td>\n",
       "      <td>[❤]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>kmdennard</td>\n",
       "      <td>[birthday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>roosvoor</td>\n",
       "      <td>[nice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>lissmits_</td>\n",
       "      <td>[😍]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>lissmits_</td>\n",
       "      <td>[HETTT]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sender             nouns\n",
       "0         roosvoor        [lekkaahh]\n",
       "1         roosvoor               [🎉]\n",
       "2         roosvoor          [nooooo]\n",
       "3    beertjelohman        [ja, zooo]\n",
       "4         roosvoor  [quality, brush]\n",
       "..             ...               ...\n",
       "253    mariannedhk               [❤]\n",
       "254      kmdennard        [birthday]\n",
       "255       roosvoor            [nice]\n",
       "256      lissmits_               [😍]\n",
       "257      lissmits_           [HETTT]\n",
       "\n",
       "[258 rows x 2 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe \n",
    "data = pd.DataFrame()\n",
    "data['sender'] = sender\n",
    "data['nouns'] = nouns\n",
    "\n",
    "# Get index of empty nouns\n",
    "row = []\n",
    "for i in range(0,len(data)):\n",
    "    if data['nouns'][i] == []:\n",
    "        row.append(i)\n",
    "\n",
    "# Create dataframe with all found nouns\n",
    "clean = data.drop(row)\n",
    "clean = clean.reset_index(drop = True)\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# OLD ################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MESSAGES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Messages file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages():\n",
    "    # Load messages.json\n",
    "    with open(json_file_mes, encoding = \"utf8\") as json_messages:\n",
    "        message = json.load(json_messages)\n",
    "\n",
    "    messages = pd.DataFrame.from_dict(message[1], \n",
    "                                              orient = 'index').T\n",
    "    for i in range(2, len(message)):\n",
    "        # Create dataframe    \n",
    "        messages = messages.append(pd.DataFrame.from_dict(message[i], \n",
    "                                              orient = 'index').T)\n",
    "\n",
    "    # Generate dataframe from message conversation \n",
    "    messages_conversation = pd.DataFrame(messages['conversation'].dropna().values.tolist())  \n",
    "    \n",
    "    return(messages_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_conversation = messages()\n",
    "file= messages_conversation[{'sender','text'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content messages_conversation\n",
    " * sender\n",
    " * created_at\n",
    " * story_share\n",
    " * text\n",
    " * media_owner\n",
    " * media_share_caption\n",
    " * media_share_url\n",
    " * mentioned_username\n",
    " * media\n",
    " * video_call_action\n",
    " * likes\n",
    " * animated_media_images\n",
    " * is_random\n",
    " * user\n",
    " * action\n",
    " * story_share_type\n",
    " * heart\n",
    " * voice_media\n",
    " * link\n",
    " * profile_share_username\n",
    " * profile_share_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables in messages_conversation with (user)names in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with only user in it\n",
    "sender = messages_conversation[messages_conversation['sender'].isna() == False]['sender']\n",
    "media_owner = messages_conversation[messages_conversation['media_owner'].isna() == False]['media_owner']\n",
    "mentioned_username = messages_conversation[messages_conversation['mentioned_username'].isna() == False]['mentioned_username']\n",
    "video_call = messages_conversation[messages_conversation['video_call_action'].isna() == False]['video_call_action']\n",
    "likes = messages_conversation[messages_conversation['likes'].isna() == False]['likes']\n",
    "action = messages_conversation[messages_conversation['action'].isna() == False]['action']\n",
    "profile_share_username = messages_conversation[messages_conversation['profile_share_username'].isna() == False]['profile_share_username']\n",
    "profile_share_name = messages_conversation[messages_conversation['profile_share_name'].isna() == False]['profile_share_name']\n",
    "\n",
    "# Columns with users in text ('s)\n",
    "story_share = messages_conversation[messages_conversation['story_share'].isna() == False]['story_share']\n",
    "\n",
    "# Columns with users tagged in text (@)\n",
    "text_tagged = messages_conversation[messages_conversation['text'].isna() == False]['text']\n",
    "media_caption_tagged = messages_conversation[messages_conversation['media_share_caption'].isna() == False]['media_share_caption']\n",
    "\n",
    "# Columns with users randomly mentioned (probably as 'actual' name, not as username)\n",
    "text_mentioned = messages_conversation[messages_conversation['text'].isna() == False]['text']\n",
    "media_caption_mentioned = messages_conversation[messages_conversation['media_share_caption'].isna() == False]['media_share_caption']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Media file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_stories():\n",
    "    # Load media.json\n",
    "    with open(json_file_med, encoding = \"utf8\") as json_media:\n",
    "        media = json.load(json_media)\n",
    "\n",
    "    media = pd.DataFrame.from_dict(media, \n",
    "            orient = 'index').T \n",
    "\n",
    "    # Generate separate DataFrames for the different lists (i.e., stories, photos, videos) in media\n",
    "    stories_media = pd.DataFrame(media['stories'].dropna().values.tolist())\n",
    "    \n",
    "    return(stories_media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_photos():\n",
    "    # Load media.json\n",
    "    with open(json_file_med, encoding = \"utf8\") as json_media:\n",
    "        media = json.load(json_media)\n",
    "\n",
    "    media = pd.DataFrame.from_dict(media, \n",
    "            orient = 'index').T \n",
    "\n",
    "    # Generate separate DataFrames for the different lists (i.e., stories, photos, videos) in media\n",
    "    photos_media  = pd.DataFrame(media['photos'].dropna().values.tolist())\n",
    "    \n",
    "    return(photos_media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_profile():\n",
    "    # Load media.json\n",
    "    with open(json_file_med, encoding = \"utf8\") as json_media:\n",
    "        media = json.load(json_media)\n",
    "\n",
    "    media = pd.DataFrame.from_dict(media, \n",
    "            orient = 'index').T \n",
    "\n",
    "    # Generate separate DataFrames for the different lists (i.e., stories, photos, videos) in media\n",
    "    profile_media = pd.DataFrame(media['profile'].dropna().values.tolist())\n",
    "    \n",
    "    return(profile_media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_videos():\n",
    "    # Load media.json\n",
    "    with open(json_file_med, encoding = \"utf8\") as json_media:\n",
    "        media = json.load(json_media)\n",
    "\n",
    "    media = pd.DataFrame.from_dict(media, \n",
    "            orient = 'index').T \n",
    "\n",
    "    # Generate separate DataFrames for the different lists (i.e., stories, photos, videos) in media\n",
    "    videos_media  = pd.DataFrame(media['videos'].dropna().values.tolist())\n",
    "    \n",
    "    return(videos_media)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>taken_at</th>\n",
       "      <th>path</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dagje naar Artis met de fam 🐒\\n#NIETWIEBELEN#j...</td>\n",
       "      <td>2020-03-06T10:52:18+00:00</td>\n",
       "      <td>photos/202003/2075921aba6fb776c498512841a02bbf...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dagje naar Artis met de fam 🐒\\n#NIETWIEBELEN#j...</td>\n",
       "      <td>2020-03-06T10:52:18+00:00</td>\n",
       "      <td>photos/202003/9af411fcc7be8bb8694554a57ddf71ae...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Dagje naar Artis met de fam 🐒\\n#NIETWIEBELEN#j...</td>\n",
       "      <td>2020-03-06T10:52:18+00:00</td>\n",
       "      <td>photos/202003/f551aa1d550fd97483e8ba865202cb80...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dagje naar Artis met de fam 🐒\\n#NIETWIEBELEN#j...</td>\n",
       "      <td>2020-03-06T10:52:18+00:00</td>\n",
       "      <td>photos/202003/735459e0859bbc9a2245eb1daf91f841...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\"Traveling is all about finding yourself\" 🌍🧘‍♀...</td>\n",
       "      <td>2020-01-21T13:40:28+00:00</td>\n",
       "      <td>photos/202001/456345dbd19f6f856ad0c0fb7c33daba...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>Groepje11 for the win!!#makingSTICSgreatagain</td>\n",
       "      <td>2017-05-16T19:25:59+00:00</td>\n",
       "      <td>photos/201705/ecbb6d3da131aa1062473723ffdf18ec...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>Groetjes uit Fryslân!! #cognitoweekend</td>\n",
       "      <td>2017-05-14T15:29:56+00:00</td>\n",
       "      <td>photos/201705/82493ccb5a7ae7965fec2d829d0352a3...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>We're on sceen! #CogniTalks#Sooooofficial</td>\n",
       "      <td>2017-04-05T15:31:24+00:00</td>\n",
       "      <td>photos/201704/005e9a149756120a204ddf85cdf1dab4...</td>\n",
       "      <td>Pakhuis De Zeijger Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>Stampot pie #fitgirl#healthy#grandparentsknowbest</td>\n",
       "      <td>2017-04-02T16:58:50+00:00</td>\n",
       "      <td>photos/201704/e741840c5ec33d0d3e12bbf40771c747...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>My life story</td>\n",
       "      <td>2017-03-30T16:36:41+00:00</td>\n",
       "      <td>photos/201703/ef964b2a8c8c4bf5b090357a381caea3...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               caption  \\\n",
       "0    Dagje naar Artis met de fam 🐒\\n#NIETWIEBELEN#j...   \n",
       "1    Dagje naar Artis met de fam 🐒\\n#NIETWIEBELEN#j...   \n",
       "2    Dagje naar Artis met de fam 🐒\\n#NIETWIEBELEN#j...   \n",
       "3    Dagje naar Artis met de fam 🐒\\n#NIETWIEBELEN#j...   \n",
       "4    \"Traveling is all about finding yourself\" 🌍🧘‍♀...   \n",
       "..                                                 ...   \n",
       "151      Groepje11 for the win!!#makingSTICSgreatagain   \n",
       "152             Groetjes uit Fryslân!! #cognitoweekend   \n",
       "153          We're on sceen! #CogniTalks#Sooooofficial   \n",
       "154  Stampot pie #fitgirl#healthy#grandparentsknowbest   \n",
       "155                                      My life story   \n",
       "\n",
       "                      taken_at  \\\n",
       "0    2020-03-06T10:52:18+00:00   \n",
       "1    2020-03-06T10:52:18+00:00   \n",
       "2    2020-03-06T10:52:18+00:00   \n",
       "3    2020-03-06T10:52:18+00:00   \n",
       "4    2020-01-21T13:40:28+00:00   \n",
       "..                         ...   \n",
       "151  2017-05-16T19:25:59+00:00   \n",
       "152  2017-05-14T15:29:56+00:00   \n",
       "153  2017-04-05T15:31:24+00:00   \n",
       "154  2017-04-02T16:58:50+00:00   \n",
       "155  2017-03-30T16:36:41+00:00   \n",
       "\n",
       "                                                  path  \\\n",
       "0    photos/202003/2075921aba6fb776c498512841a02bbf...   \n",
       "1    photos/202003/9af411fcc7be8bb8694554a57ddf71ae...   \n",
       "2    photos/202003/f551aa1d550fd97483e8ba865202cb80...   \n",
       "3    photos/202003/735459e0859bbc9a2245eb1daf91f841...   \n",
       "4    photos/202001/456345dbd19f6f856ad0c0fb7c33daba...   \n",
       "..                                                 ...   \n",
       "151  photos/201705/ecbb6d3da131aa1062473723ffdf18ec...   \n",
       "152  photos/201705/82493ccb5a7ae7965fec2d829d0352a3...   \n",
       "153  photos/201704/005e9a149756120a204ddf85cdf1dab4...   \n",
       "154  photos/201704/e741840c5ec33d0d3e12bbf40771c747...   \n",
       "155  photos/201703/ef964b2a8c8c4bf5b090357a381caea3...   \n",
       "\n",
       "                         location  \n",
       "0                             NaN  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3                             NaN  \n",
       "4                             NaN  \n",
       "..                            ...  \n",
       "151                           NaN  \n",
       "152                           NaN  \n",
       "153  Pakhuis De Zeijger Amsterdam  \n",
       "154                           NaN  \n",
       "155                           NaN  \n",
       "\n",
       "[156 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_videos()\n",
    "main_photos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct():\n",
    "    # Load media.json\n",
    "    with open(json_file_med, encoding = \"utf8\") as json_media:\n",
    "        media = json.load(json_media)\n",
    "\n",
    "    media = pd.DataFrame.from_dict(media, \n",
    "            orient = 'index').T \n",
    "\n",
    "    # Generate separate DataFrames for the different lists (i.e., stories, photos, videos) in media\n",
    "    direct_media  = pd.DataFrame(media['direct'].dropna().values.tolist())\n",
    "    \n",
    "    return(direct_media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>taken_at</th>\n",
       "      <th>location</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Good night 👋💤🌎🌞⬇️🌌🌜⬆️🌠💖 #timelapse#whereismyph...</td>\n",
       "      <td>2019-10-16T23:55:52+00:00</td>\n",
       "      <td>Lake Erie</td>\n",
       "      <td>videos/201910/e40cb11c791e46154182aff50eb7978e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  \\\n",
       "0  Good night 👋💤🌎🌞⬇️🌌🌜⬆️🌠💖 #timelapse#whereismyph...   \n",
       "\n",
       "                    taken_at   location  \\\n",
       "0  2019-10-16T23:55:52+00:00  Lake Erie   \n",
       "\n",
       "                                                path  \n",
       "0  videos/201910/e40cb11c791e46154182aff50eb7978e...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main_videos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Comments file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-06T20:22:31+00:00</td>\n",
       "      <td>@adjoayo inspiratie? ;)</td>\n",
       "      <td>the.pinklemonade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-10T16:35:04+00:00</td>\n",
       "      <td>You look so pretty!! And you too Liz 😉😋</td>\n",
       "      <td>lizzie_jmo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-17T02:22:22+00:00</td>\n",
       "      <td>@lizzie_jmo Magic🙌</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-07T22:11:10+00:00</td>\n",
       "      <td>Hier!!</td>\n",
       "      <td>doris.daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-08-19T12:08:21+00:00</td>\n",
       "      <td>Waar zijn de punani's?</td>\n",
       "      <td>doris.daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-07-22T17:08:59+00:00</td>\n",
       "      <td>Wat ben je toch fotogeniek Guusie😍</td>\n",
       "      <td>guusje002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-05-08T19:51:49+00:00</td>\n",
       "      <td>@yaramiora geen spat veranderd toch? ;)</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-05-06T16:56:19+00:00</td>\n",
       "      <td>@lieessmits 😬</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2019-05-06T16:56:00+00:00</td>\n",
       "      <td>@dieffiee dankje! 😊</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2019-05-06T16:07:28+00:00</td>\n",
       "      <td>@doris.daily 🙄🙄🙄</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2019-01-20T19:28:32+00:00</td>\n",
       "      <td>@lizzie_jmo clothes were itchy</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2018-12-22T22:56:12+00:00</td>\n",
       "      <td>Ja je kan nu mn binnenlippen zien</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2018-12-02T20:18:01+00:00</td>\n",
       "      <td>Haha jij snapt hem</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2018-10-18T14:43:05+00:00</td>\n",
       "      <td>@farliaa haha true 🙌</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2018-10-08T17:51:51+00:00</td>\n",
       "      <td>Super tof Berend!! 😊😘</td>\n",
       "      <td>beberson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2018-09-28T07:54:19+00:00</td>\n",
       "      <td>Hahaha heerlijk dit</td>\n",
       "      <td>die_ene_insta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2018-09-17T16:26:37+00:00</td>\n",
       "      <td>@doris.daily oui oui</td>\n",
       "      <td>doris.daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2018-09-17T16:25:23+00:00</td>\n",
       "      <td>Fuut fieuw</td>\n",
       "      <td>doris.daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2018-09-17T16:25:11+00:00</td>\n",
       "      <td>Lekker diiiing</td>\n",
       "      <td>doris.daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2018-08-29T05:18:24+00:00</td>\n",
       "      <td>Veel plezier 😍🎉🌈</td>\n",
       "      <td>_romyrachel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2018-07-29T20:37:50+00:00</td>\n",
       "      <td>@ieraa7 zo geschokt ben je gewoon</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2018-05-28T06:25:51+00:00</td>\n",
       "      <td>Zoooo lief!!</td>\n",
       "      <td>rubykeijzer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2018-04-19T20:05:16+00:00</td>\n",
       "      <td>INAAAA</td>\n",
       "      <td>doris.daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2018-04-08T19:46:22+00:00</td>\n",
       "      <td>@appelpartje DEAL</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2018-04-08T19:09:25+00:00</td>\n",
       "      <td>@appelpartje #lifegoals</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2018-04-06T19:56:13+00:00</td>\n",
       "      <td>@doris.daily love you too</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2018-02-22T10:05:17+00:00</td>\n",
       "      <td>Dat is wel het idee ja :)</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2018-02-21T22:54:31+00:00</td>\n",
       "      <td>Jaaaaa ga een minor doen dus ben sws 5 maanden...</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2018-02-01T17:46:29+00:00</td>\n",
       "      <td>Giiiiiirl, you're my bae(r)</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2018-01-29T13:42:05+00:00</td>\n",
       "      <td>Haha never!</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2017-12-03T21:11:32+00:00</td>\n",
       "      <td>Haha ja hoor! Casa Rosita is altijd geopend</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2017-11-29T07:24:39+00:00</td>\n",
       "      <td>Haha ja zelfgemaakte \"healthy\" bodem met haver...</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2017-07-29T12:39:28+00:00</td>\n",
       "      <td>@lizzie_jmo thankssss &lt;3</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2017-05-27T23:46:18+00:00</td>\n",
       "      <td>Herstellende ;)</td>\n",
       "      <td>roosvoor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  \\\n",
       "0   2020-03-06T20:22:31+00:00   \n",
       "1   2019-11-10T16:35:04+00:00   \n",
       "2   2019-10-17T02:22:22+00:00   \n",
       "3   2019-10-07T22:11:10+00:00   \n",
       "4   2019-08-19T12:08:21+00:00   \n",
       "5   2019-07-22T17:08:59+00:00   \n",
       "6   2019-05-08T19:51:49+00:00   \n",
       "7   2019-05-06T16:56:19+00:00   \n",
       "8   2019-05-06T16:56:00+00:00   \n",
       "9   2019-05-06T16:07:28+00:00   \n",
       "10  2019-01-20T19:28:32+00:00   \n",
       "11  2018-12-22T22:56:12+00:00   \n",
       "12  2018-12-02T20:18:01+00:00   \n",
       "13  2018-10-18T14:43:05+00:00   \n",
       "14  2018-10-08T17:51:51+00:00   \n",
       "15  2018-09-28T07:54:19+00:00   \n",
       "16  2018-09-17T16:26:37+00:00   \n",
       "17  2018-09-17T16:25:23+00:00   \n",
       "18  2018-09-17T16:25:11+00:00   \n",
       "19  2018-08-29T05:18:24+00:00   \n",
       "20  2018-07-29T20:37:50+00:00   \n",
       "21  2018-05-28T06:25:51+00:00   \n",
       "22  2018-04-19T20:05:16+00:00   \n",
       "23  2018-04-08T19:46:22+00:00   \n",
       "24  2018-04-08T19:09:25+00:00   \n",
       "25  2018-04-06T19:56:13+00:00   \n",
       "26  2018-02-22T10:05:17+00:00   \n",
       "27  2018-02-21T22:54:31+00:00   \n",
       "28  2018-02-01T17:46:29+00:00   \n",
       "29  2018-01-29T13:42:05+00:00   \n",
       "30  2017-12-03T21:11:32+00:00   \n",
       "31  2017-11-29T07:24:39+00:00   \n",
       "32  2017-07-29T12:39:28+00:00   \n",
       "33  2017-05-27T23:46:18+00:00   \n",
       "\n",
       "                                                    1                 2  \n",
       "0                             @adjoayo inspiratie? ;)  the.pinklemonade  \n",
       "1             You look so pretty!! And you too Liz 😉😋        lizzie_jmo  \n",
       "2                                  @lizzie_jmo Magic🙌          roosvoor  \n",
       "3                                              Hier!!       doris.daily  \n",
       "4                              Waar zijn de punani's?       doris.daily  \n",
       "5                  Wat ben je toch fotogeniek Guusie😍         guusje002  \n",
       "6             @yaramiora geen spat veranderd toch? ;)          roosvoor  \n",
       "7                                       @lieessmits 😬          roosvoor  \n",
       "8                                 @dieffiee dankje! 😊          roosvoor  \n",
       "9                                    @doris.daily 🙄🙄🙄          roosvoor  \n",
       "10                     @lizzie_jmo clothes were itchy          roosvoor  \n",
       "11                  Ja je kan nu mn binnenlippen zien          roosvoor  \n",
       "12                                 Haha jij snapt hem          roosvoor  \n",
       "13                               @farliaa haha true 🙌          roosvoor  \n",
       "14                              Super tof Berend!! 😊😘          beberson  \n",
       "15                                Hahaha heerlijk dit     die_ene_insta  \n",
       "16                               @doris.daily oui oui       doris.daily  \n",
       "17                                         Fuut fieuw       doris.daily  \n",
       "18                                     Lekker diiiing       doris.daily  \n",
       "19                                   Veel plezier 😍🎉🌈       _romyrachel  \n",
       "20                  @ieraa7 zo geschokt ben je gewoon          roosvoor  \n",
       "21                                       Zoooo lief!!       rubykeijzer  \n",
       "22                                             INAAAA       doris.daily  \n",
       "23                                  @appelpartje DEAL          roosvoor  \n",
       "24                            @appelpartje #lifegoals          roosvoor  \n",
       "25                          @doris.daily love you too          roosvoor  \n",
       "26                          Dat is wel het idee ja :)          roosvoor  \n",
       "27  Jaaaaa ga een minor doen dus ben sws 5 maanden...          roosvoor  \n",
       "28                        Giiiiiirl, you're my bae(r)          roosvoor  \n",
       "29                                        Haha never!          roosvoor  \n",
       "30        Haha ja hoor! Casa Rosita is altijd geopend          roosvoor  \n",
       "31  Haha ja zelfgemaakte \"healthy\" bodem met haver...          roosvoor  \n",
       "32                           @lizzie_jmo thankssss <3          roosvoor  \n",
       "33                                    Herstellende ;)          roosvoor  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load comments.json\n",
    "with open(json_file_com, encoding = \"utf8\") as json_comments:\n",
    "        comments = json.load(json_comments)\n",
    "\n",
    "comments = pd.DataFrame.from_dict(comments, \n",
    "                                      orient = 'index').T \n",
    "\n",
    "# Generate dataframe from media comments \n",
    "media_comments = pd.DataFrame(comments['media_comments'].dropna().values.tolist())\n",
    "media_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anonymize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all senders to anonimized userkeys\n",
    "def sender():\n",
    "\n",
    "    for i in range(0,len(messages_conversation.index)):\n",
    "        if messages_conversation['sender'][i] in syn_dic['user']:\n",
    "            messages_conversation['sender'][i] = syn_dic['user'][messages_conversation['sender'][i]]\n",
    "        else:\n",
    "            messages_conversation['sender'][i] = syn_dic['connections'][messages_conversation['sender'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all users mentioned in 'story_share' to anonimized userkeys\n",
    "def story_share():\n",
    "    unknown_dic = []\n",
    "    for i in range(0,len(messages_conversation.index)):\n",
    "        if isinstance(messages_conversation['story_share'][i],float):\n",
    "            continue\n",
    "        else:\n",
    "            name_string = messages_conversation['story_share'][i].split()\n",
    "            name = name_string[1].split(\"'s\")[0]\n",
    "\n",
    "            if name in syn_dic['user']:\n",
    "                syn = syn_dic['user'][name]\n",
    "            elif name in syn_dic['connections']:\n",
    "                syn = syn_dic['connections'][name]\n",
    "            else:\n",
    "                syn = randomword(10)\n",
    "                unknown = {name, syn}\n",
    "                unknown_dic.append(unknown)\n",
    "\n",
    "            messages_conversation['story_share'][i] = syn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all users mentioned in 'media_owner' to anonimized userkeys\n",
    "def media_owner():\n",
    "    \n",
    "    for i in range(0,len(messages_conversation.index)):\n",
    "        if isinstance(messages_conversation['media_owner'][i],float):\n",
    "            continue\n",
    "        else:\n",
    "            name = messages_conversation['media_owner'][i]\n",
    "\n",
    "            if name in syn_dic['user']:\n",
    "                syn = syn_dic['user'][name]\n",
    "            elif name in syn_dic['connections']:\n",
    "                syn = syn_dic['connections'][name]\n",
    "            elif name in unknown_dic:\n",
    "                syn = unknown_dic[name]\n",
    "            else:\n",
    "                syn = randomword(10)\n",
    "                unknown = {name, syn}\n",
    "                unknown_dic.append(unknown)\n",
    "\n",
    "            messages_conversation['media_owner'][i] = syn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all users mentioned in 'mentioned_username' to anonimized userkeys\n",
    "def mentioned_username():\n",
    "    \n",
    "    for i in range(0,len(messages_conversation.index)):\n",
    "        if isinstance(messages_conversation['mentioned_username'][i],float):\n",
    "            continue\n",
    "        else:\n",
    "            name = messages_conversation['mentioned_username'][i]\n",
    "\n",
    "            if name in syn_dic['user']:\n",
    "                syn = syn_dic['user'][name]\n",
    "            elif name in syn_dic['connections']:\n",
    "                syn = syn_dic['connections'][name]\n",
    "            elif name in unknown_dic:\n",
    "                syn = unknown_dic[name]\n",
    "            else:\n",
    "                syn = randomword(10)\n",
    "                unknown = {name, syn}\n",
    "                unknown_dic.append(unknown)\n",
    "\n",
    "            messages_conversation['mentioned_username'][i] = syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all tagged users mentioned in 'text' to ananimized userkeys\n",
    "def text():\n",
    "    for i in range(0,len(messages_conversation.index)):\n",
    "        if isinstance(messages_conversation['media_share_caption'][i],float):\n",
    "            continue\n",
    "        else:\n",
    "            string = messages_conversation['media_share_caption'][i]\n",
    "            split = string.split()\n",
    "            tag = []\n",
    "            for i in range(0,len(split)):\n",
    "                if split[i].find('@') == 0:\n",
    "                    tag = split[i]\n",
    "                    name = tag.split('@')[1]\n",
    "\n",
    "                    if name in syn_dic['user']:\n",
    "                        syn = syn_dic['user'][name]\n",
    "                    elif name in syn_dic['connections']:\n",
    "                        syn = syn_dic['connections'][name]\n",
    "                    elif name in unknown_dic:\n",
    "                        syn = unknown_dic[name]\n",
    "                    else:\n",
    "                        syn = randomword(10)\n",
    "                        unknown = {name, syn}\n",
    "                        unknown_dic.append(unknown) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'media_owner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-420e74fc30e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Apply anonymization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmedia_owner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mstory_share\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmentioned_username\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'media_owner' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply anonymization\n",
    "media_owner()\n",
    "story_share()\n",
    "sender()\n",
    "mentioned_username()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
